{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What you will learn?\n",
    "* How to optimize your model.\n",
    "* How to compress your model.\n",
    "* How to run it in a pre-made Android app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://media1.britannica.com/eb-media/82/73182-004-B826BA69.jpg\n",
    "mv 73182-004-B826BA69.jpg rose.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use the model we just built?\n",
    "Read [GraphDef proto, a SaverDef proto, and a set of variable values and output a GraphDef](https://www.tensorflow.org/extend/tool_developers/) \n",
    "If you ever want to convert a [Graph Def to SavedModel](https://stackoverflow.com/questions/44329185/convert-a-graph-proto-pb-pbtxt-to-a-savedmodel-for-use-in-tensorflow-serving-o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.179s\n",
      "\n",
      "roses 0.998492\n",
      "tulips 0.00149764\n",
      "sunflowers 9.80894e-06\n",
      "daisy 8.05707e-08\n",
      "dandelion 5.84384e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-14 19:48:11.679839: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-14 19:48:11.679971: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-14 19:48:11.680026: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m scripts.label_image \\\n",
    "  --graph=tf_files/retrained_graph.pb  \\\n",
    "  --image=rose.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize for inference\n",
    "To avoid problems caused by unsupported training ops, the TensorFlow installation includes a tool, optimize_for_inference, that removes all nodes that aren't needed for a given set of input and outputs.\n",
    "\n",
    "The script also does a few other optimizations that help speed up the model, such as merging explicit batch normalization operations into the convolutional weights to reduce the number of calculations. This can give a 30% speed up, depending on the input model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bash\n",
    "python -m tensorflow.python.tools.optimize_for_inference \\\n",
    "  --input=tf_files/retrained_graph.pb \\\n",
    "  --output=tf_files/optimized_graph.pb \\\n",
    "  --input_names=\"input\" \\\n",
    "  --output_names=\"final_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 11M\n",
      "drwxr-xr-x 3 root root 4.0K Dec  6 17:58 flower_photos\n",
      "-rw-r--r-- 1 root root   40 Dec  6 17:58 retrained_labels.txt\n",
      "-rw-r--r-- 1 root root 5.3M Dec  6 17:58 retrained_graph.pb\n",
      "-rw-r--r-- 1 root root 5.3M Dec  6 19:38 optimized_graph.pb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -ltrh tf_files/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the optimized model\n",
    "To check that optimize_for_inference hasn't altered the output of the network, compare the label_image output for retrained_graph.pb with that of optimized_graph.pb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.158s\n",
      "\n",
      "roses 0.998492\n",
      "tulips 0.00149764\n",
      "sunflowers 9.80894e-06\n",
      "daisy 8.05707e-08\n",
      "dandelion 5.84384e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-06 19:40:45.867020: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m scripts.label_image \\\n",
    "    --graph=tf_files/optimized_graph.pb \\\n",
    "    --image=rose.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the compression baseline\n",
    "The retrained model is still 84MB in size at this point. That large download size may be a limiting factor for any app that includes it.\n",
    "\n",
    "Every mobile app distribution system compresses the package before distribution. So test how much the graph can be compressed using the gzip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         compressed        uncompressed  ratio uncompressed_name\n",
      "            5027947             5460013   7.9% tf_files/optimized_graph.pb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gzip -c tf_files/optimized_graph.pb > tf_files/optimized_graph.pb.gz\n",
    "\n",
    "gzip -l tf_files/optimized_graph.pb.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the space taken up by the graph is by the weights, which are large blocks of floating point numbers. Each weight has a slightly different floating point value, with very little regularity.\n",
    "\n",
    "But compression works by exploiting regularity in the data, which explains the failure here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantize the network weights\n",
    "These days, we actually have a lot of models being deployed in commercial applications. The computation demands of training grow with the number of researchers, but the cycles needed for inference expand in proportion to users. That means pure inference efficiency has become a burning issue for a lot of teams. That is where quantization comes in. It's an umbrella term that covers a lot of different techniques to store numbers and perform calculations on them in more compact formats than 32-bit floating point\n",
    "\n",
    "Training neural networks is done by applying many tiny nudges to the weights, and these small increments typically need floating point precision to work. Taking a pre-trained model and running inference is very different. One of the magical qualities of deep networks is that they tend to cope very well with high levels of noise in their inputs. If you think about recognizing an object in a photo you've just taken, the network has to ignore all the CCD noise, lighting changes, and other non-essential differences between it and the training examples it's seen before, and focus on the important similarities instead. This ability means that they seem to treat low-precision calculations as just another source of noise, and still produce accurate results even with numerical formats that hold less information.\n",
    "\n",
    "More Details are [HERE](https://www.tensorflow.org/performance/quantization)\n",
    "\n",
    "It does this without any changes to the structure of the network, it simply quantizes the constants in place. [Training Quantization Research paper HERE](https://arxiv.org/abs/1609.07061)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bash\n",
    "python -m scripts.quantize_graph \\\n",
    "  --input=tf_files/optimized_graph.pb \\\n",
    "  --output=tf_files/rounded_graph.pb \\\n",
    "  --output_node_names=final_result \\\n",
    "  --mode=weights_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         compressed        uncompressed  ratio uncompressed_name\n",
      "            1633004             5460032  70.1% tf_files/rounded_graph.pb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gzip -c tf_files/rounded_graph.pb > tf_files/rounded_graph.pb.gz\n",
    "gzip -l tf_files/rounded_graph.pb.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now before you continue, verify that the quantization process hasn't had too negative an effect on the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.180s\n",
      "\n",
      "roses 0.985175\n",
      "tulips 0.0147941\n",
      "daisy 2.88691e-05\n",
      "sunflowers 1.78422e-06\n",
      "dandelion 5.62923e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-06 19:46:30.783505: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m scripts.label_image \\\n",
    "  --image=rose.jpg \\\n",
    "  --graph=tf_files/rounded_graph.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "          <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "          <script>\n",
       "            requirejs.config({\n",
       "              paths: {\n",
       "                base: '/static/base',\n",
       "              },\n",
       "            });\n",
       "          </script>\n",
       "          "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 18M\n",
      "drwxr-xr-x 3 root root 4.0K Dec  6 17:58 flower_photos\n",
      "-rw-r--r-- 1 root root   40 Dec  6 17:58 retrained_labels.txt\n",
      "-rw-r--r-- 1 root root 5.3M Dec  6 17:58 retrained_graph.pb\n",
      "-rw-r--r-- 1 root root 5.3M Dec  6 19:38 optimized_graph.pb\n",
      "-rw-r--r-- 1 root root 5.3M Dec  6 19:44 rounded_graph.pb\n",
      "-rw-r--r-- 1 root root 1.6M Dec  6 19:45 rounded_graph.pb.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -ltrh tf_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
